from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Activation          # Подключение библиотек
from tensorflow.keras.applications import VGG16

train_dir='true_train'
val_dir='true_val'
img_width=256
img_height=256
input_shape=(img_width,img_height,3)                                                                   # Установка параметров обучения
epochs=10
batch_size=64
train_samples=15850
val_samples=2500

vgg16_net = VGG16(weights='imagenet',include_top = False, input_shape = (256,256,3))                   # Загрузка сверточных слоев модели VGG16 с весами для ImageNet
vgg16_net.trainable = False

model=Sequential()
model.add(vgg16_net)
model.add(Flatten())
model.add(Dense(256))                                                                                   # Определение архитектуры нейронной сети
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(10))
model.add(Activation('softmax'))

model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=1e-5), metrics=['accuracy'])   # Установка функции потерь, метода оптимизации и метрики

datagen=ImageDataGenerator(rescale=1./255)
train_generator=datagen.flow_from_directory(train_dir, 
                                           target_size=(img_width,img_height),
                                           batch_size=batch_size,
                                           class_mode='categorical')                                         # Создание генераторов для загрузки изображений из каталогов в размере мини-батча

val_generator=datagen.flow_from_directory(val_dir, 
                                           target_size=(img_width,img_height),
                                           batch_size=batch_size,
                                           class_mode='categorical')
                                          
model.load_weights('WGGWeights_softmax.h5')                                                           # Загрузка имеющихся весов, полученный при обучении

model.fit(
train_generator,
steps_per_epoch=train_samples//batch_size,
epochs=epochs,
validation_data=val_generator,                                                                                      # Обучение нейросети методом fit
validation_steps=val_samples//batch_size)

model.save_weights('WGGWeights_softmax.h5')                                                                # Сохранение весов после обучения
