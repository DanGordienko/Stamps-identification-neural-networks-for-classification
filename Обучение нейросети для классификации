from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Activation          # Подключение библиотек
from tensorflow.keras.applications import VGG16

# Обучение происходит на сгенерированных датасетах, находящихся в 10 подкаталогах каталога class_train_images, содержащих по 1265 изображений каждый.
# Валидационные подкаталоги содержат по 320 изображений (см. Алгоритм генерации).
# Многие исходные файлы пока не загружены в репозиторий (изображения листов для фона, веса моделей, изображения для тестирования). Скоро это будет исправлено


train_dir='class_train_images'
val_dir='class_val_images'
img_width=256
img_height=256
input_shape=(img_width,img_height,3)                                                                   # Установка параметров обучения
epochs=10
batch_size=50
train_samples=12650
val_samples=3200

vgg16_net = VGG16(weights='imagenet',include_top = False, input_shape = (256,256,3))                   # Загрузка сверточных слоев модели VGG16 с весами для ImageNet
vgg16_net.trainable = False

model=Sequential()
model.add(vgg16_net)
model.add(Flatten())
model.add(Dense(256))                                                                                   # Определение архитектуры нейронной сети
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(10))
model.add(Activation('softmax'))

model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=1e-5), metrics=['accuracy'])   # Установка функции потерь, метода оптимизации и метрики

datagen=ImageDataGenerator(rescale=1./255)
train_generator=datagen.flow_from_directory(train_dir, 
                                           target_size=(img_width,img_height),
                                           batch_size=batch_size,
                                           class_mode='categorical')                                         # Создание генераторов для загрузки изображений из каталогов в размере мини-батча

val_generator=datagen.flow_from_directory(val_dir, 
                                           target_size=(img_width,img_height),
                                           batch_size=batch_size,
                                           class_mode='categorical')
                                          
model.load_weights('WGGWeights_softmax.h5')                                                           # Загрузка имеющихся весов, полученный при обучении (файл весов загружен в репозиторий)

model.fit(
train_generator,
steps_per_epoch=train_samples//batch_size,
epochs=epochs,
validation_data=val_generator,                                                                                      # Обучение нейросети методом fit
validation_steps=val_samples//batch_size)

model.save_weights('WGGWeights_softmax.h5')                                                                # Сохранение весов после обучения
